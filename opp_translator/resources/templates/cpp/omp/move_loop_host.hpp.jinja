{% extends "cpp/loop_host.hpp.jinja" %}
{% import "cpp/move_loop_dh_init_host.hpp.jinja" as dh %}

{%- macro arg_to_pointer(arg) %}
    {%- if arg is gbl %}
        {%- set cast = arg.typ -%}
        ({{cast}} *)args[{{arg.id}}].data
    {%- else -%}
        {%- set cast = lh.dat(arg).typ -%}
    
        {%- if arg is direct -%}
            {%- if lh is injected_loop -%}
            {%- set offset = "(inj_start + n)" -%}
            {%- else -%}
            {%- set offset = "n" -%}
            {%- endif -%}
        {%- elif arg is double_indirect -%}
            {%- set offset = "map%s[%d]" % (arg.map_id, arg.map_idx) -%}
        {%- elif arg is p2c_mapped -%}
            {%- set offset = "opp_p2c[0]" -%}
        {%- elif arg is indirect -%}
            {%- set offset = "map%s[%d]" % (arg.map_id, arg.map_idx) -%}
        {%- endif -%}

        {%- if arg is not gbl %}
            {%- set offset = " + (%s * %d)" % (offset, lh.dat(arg).dim) %}
        {%- endif -%}

        {%- if lh is indirect and arg is gbl and arg is reduction -%}
            arg{{arg.id}}_local
        {%- elif lh is indirect and arg is dat and arg is reduction -%}
            arg{{arg.id}}_thread_data{{offset}}
        {%- else -%}
            ({{"const " if arg.access_type == OP.AccessType.READ}}{{cast}} *)args[{{arg.id}}].data{{offset}}
        {%- endif -%}
    {%- endif -%}
{%- endmacro -%}

{% block host_prologue %}
void opp_particle_move__{{lh.kernel}}(opp_set set, opp_map c2c_map, opp_map p2c_map,
    {% for arg in lh.args %}
    opp_arg arg{{arg.id}}{{"," if not loop.last}} // {% if arg is dat %}{{lh.dat(arg).ptr}} {% endif -%} | OPP_{{arg.access_type.name}}
    {% endfor %}
) 
{
    if (OPP_DBG) opp_printf("APP", "opp_particle_move__{{lh.kernel}} set_size %d", set->size);

    opp_profiler->start("{{lh.kernel}}");

    const int nthreads = omp_get_max_threads();

    const int nargs = {{lh.args|length + 1}};
    opp_arg args[nargs];

    {% for arg in lh.args %}
    args[{{loop.index0}}] = {{arg_dat_redef(arg) if lh.args[arg.id] is vec else "arg%d" % arg.id}};
    {% endfor %}
    args[{{lh.args|length}}] = opp_arg_dat(p2c_map->p2c_dat, OPP_RW); // required to make dirty or should manually make it dirty

    OPP_mesh_relation_data = (OPP_INT*)p2c_map->p2c_dat->data;

    opp_mpi_halo_exchanges{{"_grouped" if config.grouped-}}
        (set, nargs, args{{(", %d" % config.device) if config.grouped}});

    {% for arg in lh.args|dat|reduction|not_already_mapped(lh) if lh is indirect %}
    opp_create_thread_level_data<{{lh.dat(arg).typ}}>(args[{{arg.id}}], 0);
    {% endfor %}        
    opp_mpi_halo_wait_all{{"_grouped" if config.grouped-}}
        (nargs, args{{", 1" if config.grouped}});

    {% for arg in lh.args|gbl|reduction if lh is indirect %}
    {{arg.typ}} arg{{arg.id}}_local[{{arg.dim}}] = {0};{{"\n" if loop.last}}
    {% endfor %}
    {% for arg in lh.args|gbl|reduction if lh is indirect and arg is not inc %}
    memcpy(arg{{arg.id}}_local, arg{{idx}}.data, {{arg.dim}} * sizeof({{arg.typ}}));{{"\n" if loop.last}}
    {% endfor %}
{% endblock %}

{% block host_loop %}
    // lambda function for multi hop particle movement
    auto multihop_mover = [&](const int n, const int thread
    {%- for arg in lh.args|dat|reduction|not_already_mapped(lh) if lh is indirect -%}
        , {{lh.dat(arg).typ}}* arg{{arg.id}}_thread_data
    {%- endfor -%}) {

        OPP_INT *opp_p2c = OPP_mesh_relation_data + n;

        if (opp_p2c[0] == MAX_CELL_INDEX) {
            return;
        }

        OPP_INT *opp_c2c = nullptr;
        char move_flag = OPP_MOVE_DONE;
        bool iter_one_flag = true;

        do {
            move_flag = OPP_MOVE_DONE;
            opp_c2c = c2c_map->map + (opp_p2c[0] * {{lh.c2c_map.dim}});

            opp_k{{kernel_idx}}::{{lh.kernel}}(
                move_flag, iter_one_flag, opp_c2c, opp_p2c, 
            {% for arg in lh.args %}
                {{arg_to_pointer(arg)}}{{"," if not loop.last}}
            {% endfor %}
            );

        } while (opp_check_part_move_status(move_flag, iter_one_flag, opp_p2c[0], n, thread));
    };

    // ----------------------------------------------------------------------------
    opp_init_particle_move(set, 0, nullptr);
    const int total_count = OPP_iter_end - OPP_iter_start;

{% if lh.dh_loop_required %}
    if (useGlobalMove) { // For now Global Move will not work with MPI

#ifdef USE_MPI         
        globalMover->initGlobalMove();
#endif

        opp_profiler->start("GblMv_Move");

        // check whether particles needs to be moved over global move routine
        #pragma omp parallel for
        for (int thr = 0; thr < nthreads; thr++)
        {
            const size_t start  = ((size_t)total_count * thr) / nthreads;
            const size_t finish = ((size_t)total_count * (thr+1)) / nthreads;

            for (size_t i = start; i < finish; i++)
            {
                OPP_INT* opp_p2c = OPP_mesh_relation_data + i;
                // TODO: we assume pos is in arg 0, Change this!
                const opp_point* point = (const opp_point*)&(((OPP_REAL*)args[0].data)[i * {{lh.dat(lh.args[0]).dim}}]); 

                // check for global move, and if satisfy global move criteria, then remove the particle from current rank
                if (opp_part_checkForGlobalMove{{lh.dat(lh.args[0]).dim}}D(set, *point, i, opp_p2c[0], thr)) { 
                    
                    part_remove_count_per_thr[thr] += 1;
                    continue;  
                }
            }
        }

        opp_profiler->end("GblMv_Move");

#ifdef USE_MPI 
        opp_gather_gbl_move_indices();
        globalMover->communicate(set);
#endif
    }
{% endif %}

    opp_profiler->start("Mv_AllMv0");

    // ----------------------------------------------------------------------------
    // check whether all particles not marked for global comm is within cell, 
    // and if not mark to move between cells within the MPI rank, mark for neighbour comm
    opp_profiler->start("{{lh.kernel}}_only");
    #pragma omp parallel for
    for (int thr = 0; thr < nthreads; thr++)
    {
        const size_t start  = OPP_iter_start + ((size_t)total_count * thr) / nthreads;
        const size_t finish = OPP_iter_start + ((size_t)total_count * (thr+1)) / nthreads;
    {% for arg in lh.args|dat|reduction|not_already_mapped(lh) if lh is indirect %}
    
        {{lh.dat(arg).typ}}* arg{{arg.id}}_thread_data = ({{lh.dat(arg).typ}}*)((*(args[{{arg.id}}].dat->thread_data))[thr]);
    {% endfor %}

        for (size_t i = start; i < finish; i++)
        {   
            multihop_mover(i, thr
    {%- for arg in lh.args|dat|reduction|not_already_mapped(lh) if lh is indirect -%}
                , arg{{arg.id}}_thread_data
    {%- endfor -%});
        }
    }
    opp_profiler->end("{{lh.kernel}}_only");

    opp_profiler->end("Mv_AllMv0");

{% if lh.dh_loop_required %}
#ifdef USE_MPI 
    // ----------------------------------------------------------------------------
    // finalize the global move routine and iterate over newly added particles and check whether they need neighbour comm
    if (useGlobalMove && globalMover->finalize(set) > 0) {
        
        opp_profiler->start("GblMv_AllMv");

        // need to change arg data since particle resize in globalMover::finalize could change the pointer in dat->data 
        for (int i = 0; i < nargs; i++)
            if (args[i].argtype == OPP_ARG_DAT && args[i].dat->set->is_particle)
                args[i].data = args[i].dat->data;

        // check whether the new particle is within cell, and if not move between cells within the MPI rank, 
        // mark for neighbour comm. Do only for the globally moved particles 
        opp_profiler->start("{{lh.kernel}}_only");
        const int iter_start = (set->size - set->diff);
        const int iter_count = set->diff;
        #pragma omp parallel for
        for (int thr = 0; thr < nthreads; thr++)
        {
            const size_t start  = iter_start + ((size_t)iter_count * thr) / nthreads;
            const size_t finish = iter_start + ((size_t)iter_count * (thr+1)) / nthreads;
    {% for arg in lh.args|dat|reduction|not_already_mapped(lh) if lh is indirect %}
    
            {{lh.dat(arg).typ}}* arg{{arg.id}}_thread_data = ({{lh.dat(arg).typ}}*)((*(args[{{arg.id}}].dat->thread_data))[thr]);
    {% endfor %}

            for (size_t i = start; i < finish; i++)
            {   
                multihop_mover(i, thr
    {%- for arg in lh.args|dat|reduction|not_already_mapped(lh) if lh is indirect -%}
                , arg{{arg.id}}_thread_data
    {%- endfor -%});
            }        
        }
        opp_profiler->end("{{lh.kernel}}_only");

        opp_profiler->end("GblMv_AllMv");
    }
#endif
{% endif %}

    // ----------------------------------------------------------------------------
    // Do neighbour communication and if atleast one particle is received by the currect rank, 
    // then iterate over the newly added particles
    while (opp_finalize_particle_move(set)) {
        
        const std::string profName = std::string("Mv_AllMv") + std::to_string(OPP_comm_iteration);
        opp_profiler->start(profName);
        
        opp_init_particle_move(set, 0, nullptr);

        // check whether particle is within cell, and if not move between cells within the MPI rank, mark for neighbour comm
        opp_profiler->start("{{lh.kernel}}_only");
        const int iter_count = (OPP_iter_end - OPP_iter_start);
        #pragma omp parallel for
        for (int thr = 0; thr < nthreads; thr++)
        {
            const size_t start  = OPP_iter_start + ((size_t)iter_count * thr) / nthreads;
            const size_t finish = OPP_iter_start + ((size_t)iter_count * (thr+1)) / nthreads;
    {% for arg in lh.args|dat|reduction|not_already_mapped(lh) if lh is indirect %}
    
            {{lh.dat(arg).typ}}* arg{{arg.id}}_thread_data = ({{lh.dat(arg).typ}}*)((*(args[{{arg.id}}].dat->thread_data))[thr]);
    {% endfor %}

            for (size_t i = start; i < finish; i++)
            {   
                multihop_mover(i, thr
    {%- for arg in lh.args|dat|reduction|not_already_mapped(lh) if lh is indirect -%}
                , arg{{arg.id}}_thread_data
    {%- endfor -%});
            }
        }
        opp_profiler->end("{{lh.kernel}}_only");

        opp_profiler->end(profName);
    }
{% endblock %}

{% block host_epilogue %}

    {% for arg in lh.args|dat|reduction|not_already_mapped(lh) if lh is indirect %}
    opp_reduce_thread_level_data<{{lh.dat(arg).typ}}>(args[{{arg.id}}]);
    {% endfor %}
    {% for arg in lh.args|gbl|reduction %}
#ifdef USE_MPI 
    opp_mpi_reduce(&args[{{arg.id}}], ({{arg.typ}} *)args[{{arg.id}}].data);
#endif
    {% endfor %}

    opp_set_dirtybit(nargs, args);

{{super()}}
{% endblock %}

{% block dh_init_wrapper %}
{% if lh.dh_loop_required %}
{{ dh.init_dh(lh,kernel_idx,config.omp) }}
{% endif %}
{% endblock %}